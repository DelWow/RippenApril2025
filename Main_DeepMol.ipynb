{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DelWow/RippenApril2025/blob/main/Main_DeepMol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**\n",
        "\n",
        "Before running any of the code, I recommend having a quick look over the guide I have started working on for this notebook. Make sure your runtime is set to a t4 gpu as Colab automatically sets it to a cpu."
      ],
      "metadata": {
        "id": "2-sXYX35GY5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First Cells**"
      ],
      "metadata": {
        "id": "09NBNHpiHXDZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ldFH51Vjmnu"
      },
      "outputs": [],
      "source": [
        "####This is super important, do not restart runtime while this block is still running, runtime should be restarted ONLY after this block is done running even if an option of restarting runtime is given before the cell ends.\n",
        "#This cell is still super messy and needs to be cleaned up but this should be enough to start generating molecules and featurization\n",
        "#Set up process\n",
        "!pip install numpy\n",
        "!pip install pandas==2.1.4\n",
        "!pip install rdkit-pypi\n",
        "!pip install deepmol\n",
        "!pip install deepmol scikit-learn\n",
        "!pip install git+https://github.com/samoturk/mol2vec#egg=mol2vec\n",
        "!pip install biosynfoni\n",
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade --force-reinstall \"numpy<2\" \"pandas<=2.0.3\" \"scikit-learn<1.6\" \"rdkit==2023.9.6\" \"deepmol\n",
        "!pip install dill\n",
        "#Restart runtime after this cell is done running"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run top cell first before this one\n",
        "#I do not recommend running this cell more than once per runtime as it can lead to errors when it comes to the file pathway of REINVENT4\n",
        "#Install reinvent\n",
        "!git clone --depth 1 https://github.com/MolecularAI/REINVENT4.git\n",
        "%cd REINVENT4\n",
        "\n",
        "#CPU or GPU install\n",
        "#!python install.py cpu -d none #This installs for the cpu\n",
        "!python install.py cu124 -d none #This installs for the gpu\n",
        "\n"
      ],
      "metadata": {
        "id": "deGoA0SARIlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Second Cells**"
      ],
      "metadata": {
        "id": "bjxZuws8HaEm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVoybRWGV2QO"
      },
      "outputs": [],
      "source": [
        "#These 3 imports are mostly likely to cause any failures\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.io.formats import format as pandas_format\n",
        "\n",
        "# Without this if statement RDkit doesnt work for some reason\n",
        "# RDKit just needs the attribute to exist, the return value is never actually used for your featurization. A proper fix for this error will be implemented soon.\n",
        "if not hasattr(pandas_format, 'get_adjustment'):\n",
        "    def get_adjustment(self, col, cell):\n",
        "        return None\n",
        "    pandas_format.get_adjustment = get_adjustment\n",
        "\n",
        "#Continue imports\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import deepmol\n",
        "from deepmol.loaders import CSVLoader\n",
        "from deepmol.models import SklearnModel\n",
        "from deepmol.compound_featurization import MorganFingerprint\n",
        "from rdkit import DataStructs\n",
        "\n",
        "\n",
        "# Load dataset (assuming a CSV file with SMILES and labels)\n",
        "loader = CSVLoader(dataset_path='/content/enumerated_smiles (1).csv', smiles_field=\"Enumerated_SMILES\") # This is for our existing database\n",
        "dataset = loader.create_dataset()\n",
        "genLoader = CSVLoader(dataset_path='/content/generated.csv', smiles_field=\"SMILES\") #This is meant for newly generated SMILES\n",
        "genDataset = genLoader.create_dataset()\n",
        "print(dataset.get_shape()) #Print shape, used for debugging purposes\n",
        "print(genDataset.get_shape()) #Print shape, used for debugging purposes\n",
        "%cd /content\n",
        "\n",
        "# Apply molecular featurization\n",
        "featurizer = MorganFingerprint(radius=2, size=128) # Will featurize as ECFP2, radius and size can be changed\n",
        "featurizer.featurize(dataset, inplace=True)\n",
        "featurizer.featurize(genDataset, inplace=True)\n",
        "\n",
        "#Creates a new csv file and transfers featurized smiles into it\n",
        "features_df = pd.DataFrame(dataset.X)\n",
        "features_df['SMILES'] = dataset.smiles\n",
        "features_df.to_csv('featurized_dataset.csv', index=False)\n",
        "print(\"featurized_dataset.csv has been generated.\")\n",
        "\n",
        "##Next portion is for computing similaritys (Potentially wrong, need to review), This code can take super longer to run depending the bit length size\n",
        "\n",
        "#genDataset.X and dataset.X are DeepMol-featurized (binary fingerprints)\n",
        "def tanimoto_np(fp1, fp2):\n",
        "    intersection = np.dot(fp1, fp2)\n",
        "    return intersection / (np.sum(fp1) + np.sum(fp2) - intersection + 1e-10)  #+1e-10 is added to remove division by 0 even if it is not a part of the formula\n",
        "\n",
        "# Compute pairwise Tanimoto similarity\n",
        "similarities = []\n",
        "for gen_fp in genDataset.X:\n",
        "    row = [tanimoto_np(gen_fp, db_fp) for db_fp in dataset.X]\n",
        "    similarities.append(row)\n",
        "\n",
        "#Puts our similaritoes into a a new csv\n",
        "similarities_df = pd.DataFrame(similarities)\n",
        "similarities_df.to_csv(\"tanimoto_similarities.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Third Cell**"
      ],
      "metadata": {
        "id": "TZb6acyAHeuP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEuLU3xLZb1i"
      },
      "outputs": [],
      "source": [
        "###Note this code will probably fail the first time it runs, but should run properly the second time and will take about 3-5 minutes to run of the default parameters\n",
        "#Needed imports\n",
        "import pandas as pd, textwrap, subprocess, os, sys\n",
        "\n",
        "SMILES_PATH = \"/content/enumerated_smiles (1).csv\"    # change if your file lives elsewhere\n",
        "LIMIT = 10000  # number of entries\n",
        "\n",
        "smiles = pd.read_csv(SMILES_PATH, header=None, nrows=LIMIT).iloc[:, 0].astype(str) #To do all entires, just remove the nrows=LIMIT slice (or set LIMIT=None) so Pandas reads the whole file:\n",
        "smiles.to_csv(\"train.smi\", index=False, header=False)\n",
        "print(f\"Prepared train.smi with {len(smiles)} molecules\")\n",
        "%cd /content/REINVENT4\n",
        "\n",
        "# write a tiny transfer-learning config (GPU) *NOTE refer to user guide to understand how epochs and batch size work\n",
        "tl_toml = textwrap.dedent(\"\"\"\n",
        "    run_type = \"transfer_learning\"\n",
        "    device   = \"cuda:0\"\n",
        "\n",
        "    [parameters]\n",
        "    num_epochs  = 10\n",
        "    batch_size  = 64\n",
        "    input_model_file       = \"priors/reinvent.prior\"\n",
        "    smiles_file            = \"train.smi\"\n",
        "    validation_smiles_file = \"train.smi\"\n",
        "    output_model_file      = \"tiny.model\"\n",
        "\"\"\")\n",
        "open(\"my_tl.toml\", \"w\").write(tl_toml)\n",
        "\n",
        "\n",
        "#fine-tune the RNN\n",
        "os.chdir('/content/REINVENT4')\n",
        "#A decent amount of errors can be caused by the next line. This is usually because the 'reinvent' file is not being read properly.\n",
        "#A common fix that I found is just rerunning this cell will somehow solve this problem. Proper fix is needed for this but as of right now I have no idea why this error occurs.\n",
        "subprocess.run([\"reinvent\", \"-l\", \"tl.log\", \"my_tl.toml\"], check=True)\n",
        "\n",
        "\n",
        "# sampling config (GPU) *Note change num_smiles to amount of smiles you want to be generated\n",
        "sample_toml = textwrap.dedent(\"\"\"\n",
        "    run_type = \"sampling\"\n",
        "    device   = \"cuda:0\"\n",
        "\n",
        "    [parameters]\n",
        "    model_file   = \"tiny.model\"\n",
        "    output_file  = \"generated.csv\"\n",
        "    num_smiles   = 500\n",
        "    unique_molecules = true\n",
        "    randomize_smiles = true\n",
        "\"\"\")\n",
        "open(\"sample.toml\", \"w\").write(sample_toml)\n",
        "\n",
        "# generate new molecules\n",
        "subprocess.run([\"reinvent\", \"-l\", \"sample.log\", \"sample.toml\"], check=True)\n",
        "\n",
        "print(\"\\n  Done! 500 molecules saved to generated.csv\") # This is located in /content/REINVENT4/generated.csv, refer to user guide to understand how the NLL works\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validity Reports on SMILES**"
      ],
      "metadata": {
        "id": "l2AmL6dLmD7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This code isnt needed, just meant to check if our SMILES are valid\n",
        "#This will check if smiles are valid using RDkit and put them into 3 csvs, 1 containing all smiles with their validity, 1 containing only valid smiles, and 1 containing only invalid smiles\n",
        "\n",
        "df = pd.read_csv('/content/generated.csv')\n",
        "def isValid(smi):\n",
        "  return Chem.MolFromSmiles(smi) is not None\n",
        "\n",
        "df['Valid'] = df['SMILES'].apply(isValid)\n",
        "df.to_csv(\"SmilesValidity.csv\", index = False)\n",
        "\n",
        "df[df['Valid']].to_csv(\"SmilesThatAreValid.csv\", index = False)\n",
        "df[~df['Valid']].to_csv(\"SmilesThatAreInvalid.csv\", index = False)\n"
      ],
      "metadata": {
        "id": "WdjS54pAmHLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trouble Shooting**\n",
        "\n",
        "The following is some of the common trouble shooting methods I used find erros in my code. Refer to user guide to see how they are used."
      ],
      "metadata": {
        "id": "X3i4yxpu_Bpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/REINVENT4\n",
        "!python install.py cu124 -d none     # or cu121 if cu124 fails"
      ],
      "metadata": {
        "id": "6Re5U_2C_AtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if you are running off gpu\n",
        "import torch\n",
        "assert torch.cuda.is_available(), \"still no GPU!\""
      ],
      "metadata": {
        "id": "KzhaUnAm_OQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To move misplaced files or folders\n",
        "%mv /content/YOURFILEORFOLDER/content/REINVENT4/\n"
      ],
      "metadata": {
        "id": "r8VEYVDe_vPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checks if you are on gpu and if NVIDIA table is functioning\n",
        "import torch, os, subprocess, platform\n",
        "print(\"torch cuda available:\", torch.cuda.is_available())\n",
        "print(\"CUDA version       :\", torch.version.cuda)\n",
        "subprocess.run([\"nvidia-smi\"], check=False)   # prints a table on GPU runtimes\n"
      ],
      "metadata": {
        "id": "k2Wag_Y9-tRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prints past 50 logs\n",
        "!head -n 50 tl.log"
      ],
      "metadata": {
        "id": "PhsrqIiQSebD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!which reinvent\n",
        "!reinvent --help"
      ],
      "metadata": {
        "id": "kuPDPoClSpjI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}